import yaml
import torch
from torch import nn
from loguru import logger
import os
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from utils import *
from models.dataset import SetTransformerDataset, collate_fn
from models.models import SetTransformer
import click
import time
import math
import datetime
import numpy as np
import tqdm
import shutil
import wandb
import h5py


@click.command("generate_embeddings")
@click.option("--model_path", type=str, default='/home/triniborrell/home/projects/sleepfm-clinical/sleepfm/pretrained_model/')
@click.option("--dataset_name", type=str, default='jd144')
@click.option("--channel_groups_path", type=str, default='/home/triniborrell/home/projects/sleepfm-clinical/sleepfm/configs/channel_groups_egi_fixed.json')
@click.option("--split_path", type=str, default='/home/triniborrell/home/projects/sleepfm-clinical/sleepfm/configs/dataset_split_new.json')
@click.option("--splits", type=str, default='train,validation,test')
@click.option("--num_workers", type=int, default=16)
@click.option("--batch_size", type=int, default=128)
def generate_embeddings(
    model_path,
    dataset_name, 
    channel_groups_path, 
    split_path,
    splits,
    num_workers, 
    batch_size
):
    config_path = os.path.join(model_path, "config.json")
    config = load_config(config_path)
    channel_groups = load_data(channel_groups_path)

    current_timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")

    dataset_name = dataset_name.lower()

    output = os.path.join(model_path, f"{dataset_name}")
    output_5min_agg = os.path.join(model_path, f"{dataset_name}_5min_agg")
    os.makedirs(output, exist_ok=True)
    os.makedirs(output_5min_agg, exist_ok=True)

    modality_types = config["modality_types"]
    in_channels = config["in_channels"]
    patch_size = config["patch_size"]
    embed_dim = config["embed_dim"]
    num_heads = config["num_heads"]
    num_layers = config["num_layers"]
    pooling_head = config["pooling_head"]
    dropout = 0.0

    data_path = config["data_path"]

    logger.info(f"Output Path: {output}")
    logger.info(f"Output 5 Min Agg Path: {output_5min_agg}")
    logger.info(f"modality_types: {modality_types}")

    logger.info(f"Batch Size: {batch_size}; Number of Workers: {num_workers}")

    device = torch.device("cpu")
    logger.info(f"Device set to CPU")

    start = time.time()
    split_dataset = load_data(split_path)
    splits = splits.split(",")

    # Debug: Print split dataset info
    logger.info(f"Split dataset keys: {list(split_dataset.keys())}")
    for split in splits:
        logger.info(f"Split '{split}' has {len(split_dataset.get(split, []))} files")

    if dataset_name.lower() in ["shhs1", "shhs2"]:
        path_to_data = os.path.join(data_path, f"SHHS/{dataset_name}")
        if not os.path.exists(path_to_data):
            logger.error(f"SHHS data path does not exist: {path_to_data}")
            return
        hdf5_paths = [os.path.join(path_to_data, file_name) for file_name in os.listdir(path_to_data) if file_name.endswith('.hdf5')]
    else:
        hdf5_paths = []
        for split in splits:
            if split not in split_dataset:
                logger.warning(f"Split '{split}' not found in dataset split file")
                continue
            filtered_files = [fp for fp in split_dataset[split] if dataset_name in fp.lower()]
            logger.info(f"Split '{split}': Found {len(filtered_files)} files matching dataset '{dataset_name}'")
            logger.debug(f"Filtered files: {filtered_files}")
            
            # Fallback: if no files match dataset name, use all files from split
            if len(filtered_files) == 0 and len(split_dataset[split]) > 0:
                logger.warning(f"No files matched dataset name '{dataset_name}' in split '{split}'")
                logger.info(f"Available files in split '{split}': {split_dataset[split]}")
                logger.info(f"Using all files from split '{split}' as fallback")
                filtered_files = split_dataset[split].copy()
            
            hdf5_paths += filtered_files
        
        # Check if data_path should be the preprocessing output directory
        if data_path.endswith('/eeg') and '/nice_epochs2/' in data_path:
            # This looks like raw FIF data path, use preprocessing output instead
            preprocessing_output = '/home/triniborrell/home/projects/sleepfm-clinical/output'
            logger.warning(f"Data path appears to be raw FIF data: {data_path}")
            logger.info(f"Using preprocessing output directory: {preprocessing_output}")
            data_path = preprocessing_output
        
        hdf5_paths = [os.path.join(data_path, file) for file in hdf5_paths]
        
        # Verify files exist
        existing_paths = []
        for path in hdf5_paths:
            if os.path.exists(path):
                existing_paths.append(path)
            else:
                logger.warning(f"File not found: {path}")
        hdf5_paths = existing_paths

    logger.info(f"Number of files to process: {len(hdf5_paths)}")
    if len(hdf5_paths) == 0:
        logger.error("No files found to process. Check:")
        logger.error(f"1. Data path: {data_path}")
        logger.error(f"2. Dataset name: {dataset_name}")
        logger.error(f"3. Split file: {split_path}")
        logger.error(f"4. File extensions in data directory: {os.listdir(data_path) if os.path.exists(data_path) else 'Directory not found'}")
        return

    dataset = SetTransformerDataset(config, channel_groups, hdf5_paths=hdf5_paths, split="test")
    dataloader = torch.utils.data.DataLoader(dataset, 
                                             batch_size=batch_size, 
                                             num_workers=num_workers, 
                                             shuffle=False, 
                                             collate_fn=collate_fn)

    logger.info(f"Dataset loaded in {time.time() - start:.1f} seconds")

    model_class = getattr(sys.modules[__name__], config['model'])
    logger.info(f"Model Class: {config['model']}")
    model = model_class(in_channels, patch_size, embed_dim, num_heads, num_layers, pooling_head=pooling_head, dropout=dropout)
    if device.type == "cuda":
        model = torch.nn.DataParallel(model)
    model.to(device)
    total_layers, total_params = count_parameters(model)
    logger.info(f'Trainable parameters: {total_params / 1e6:.2f} million')
    logger.info(f'Number of layers: {total_layers}')


    checkpoint = torch.load(os.path.join(model_path, "best.pt"), map_location=torch.device('cpu'))
    # Remove 'module.' prefix from checkpoint keys (saved with DataParallel)
    state_dict = checkpoint["state_dict"]
    state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}
    model.load_state_dict(state_dict)
    model.eval()

    with torch.no_grad():
        with tqdm.tqdm(total=len(dataloader)) as pbar:
            for batch in dataloader:
                batch_data, mask_list, file_paths, dset_names_list, chunk_starts = batch
#                (bas, resp, ekg, emg) = batch_data
                bas = batch_data
#                (mask_bas, mask_resp, mask_ekg, mask_emg) = mask_list
                mask_bas = mask_list

                bas = bas.to(device, dtype=torch.float)
                resp = resp.to(device, dtype=torch.float)
                ekg = ekg.to(device, dtype=torch.float)
                emg = emg.to(device, dtype=torch.float)

                mask_bas = mask_bas.to(device, dtype=torch.bool)
                mask_resp = mask_resp.to(device, dtype=torch.bool)
                mask_ekg = mask_ekg.to(device, dtype=torch.bool)
                mask_emg = mask_emg.to(device, dtype=torch.bool)

                embeddings = [
                    model(bas, mask_bas),
                    model(resp, mask_resp),
                    model(ekg, mask_ekg),
                    model(emg, mask_emg),
                ]

                embeddings_new = [e[0].unsqueeze(1) for e in embeddings]

                for i in range(len(file_paths)):
                    file_path = file_paths[i]
                    chunk_start = chunk_starts[i]
                    subject_id = os.path.basename(file_path).split('.')[0]
                    output_path = os.path.join(output_5min_agg, f"{subject_id}.hdf5")

                    with h5py.File(output_path, 'a') as hdf5_file:
                        for modality_idx, modality_type in enumerate(config["modality_types"]):
                            if modality_type in hdf5_file:
                                dset = hdf5_file[modality_type]
                                chunk_start_correct = chunk_start // (embed_dim * 5 * 60)
                                chunk_end = chunk_start_correct + embeddings_new[modality_idx][i].shape[0]
                                if dset.shape[0] < chunk_end:
                                    dset.resize((chunk_end,) + embeddings_new[modality_idx][i].shape[1:])
                                dset[chunk_start_correct:chunk_end] = embeddings_new[modality_idx][i].cpu().numpy()
                            else:
                                hdf5_file.create_dataset(modality_type, data=embeddings_new[modality_idx][i].cpu().numpy(), chunks=(embed_dim,) + embeddings_new[modality_idx][i].shape[1:], maxshape=(None,) + embeddings_new[modality_idx][i].shape[1:])

                embeddings_new = [e[1] for e in embeddings]

                for i in range(len(file_paths)):
                    file_path = file_paths[i]
                    chunk_start = chunk_starts[i]
                    subject_id = os.path.basename(file_path).split('.')[0]
                    output_path = os.path.join(output, f"{subject_id}.hdf5")

                    with h5py.File(output_path, 'a') as hdf5_file:
                        for modality_idx, modality_type in enumerate(config["modality_types"]):
                            if modality_type in hdf5_file:
                                dset = hdf5_file[modality_type]
                                chunk_start_correct = chunk_start // (embed_dim * 5)
                                chunk_end = chunk_start_correct + embeddings_new[modality_idx][i].shape[0]
                                if dset.shape[0] < chunk_end:
                                    dset.resize((chunk_end,) + embeddings_new[modality_idx][i].shape[1:])
                                dset[chunk_start_correct:chunk_end] = embeddings_new[modality_idx][i].cpu().numpy()
                            else:
                                hdf5_file.create_dataset(modality_type, data=embeddings_new[modality_idx][i].cpu().numpy(), chunks=(embed_dim,) + embeddings_new[modality_idx][i].shape[1:], maxshape=(None,) + embeddings_new[modality_idx][i].shape[1:])
                pbar.update()


class Identity(torch.nn.Module):
    def __init__(self):
        super().__init__()
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return x


if __name__ == '__main__':
    generate_embeddings()